# Task 02.3: Background Aggregation Service

**Phase:** 02 - Backend - F001: Public Contract Aggregation
**Parent Plan:** [MVP Implementation Plan Overview](../00-mvp-implementation-plan-overview.md)
**Last Updated:** 2025-06-06

## 1. Objective

To implement a background service/task that periodically fetches public contract data from ESI for relevant regions, processes it, and stores/updates it in the local database using the defined data models and ESI client.

## 2. Relevant Specifications

*   `../../../design/design-spec.md` (Sections: Background Processing, Data Aggregation)
*   `../../../design/features/F001-Public-Contract-Aggregation-Display.md` (Data freshness requirements)
*   Task 02.1: ESI API Client (Public Endpoints)
*   Task 02.2: Data Models for F001

## 3. Key Implementation Steps

*   [ ] **Choose Background Task Framework:**
    *   Select a suitable framework for running background tasks with FastAPI (e.g., `FastAPI BackgroundTasks`, `Celery`, `ARQ`). For MVP, `FastAPI BackgroundTasks` or a simple scheduled script might suffice. `ARQ` is a good async-native option.
    *   **Decision Point:** For MVP, a simple scheduled task (e.g., using `APScheduler` within the FastAPI app or a separate script run by `cron`/`Scheduled Tasks`) might be simpler than full Celery/ARQ setup. Let's lean towards `APScheduler` integrated with FastAPI for now.
*   [ ] **Aggregation Logic:**
    *   Define the core aggregation function/service class.
    *   Iterate through target EVE Online regions (initially a configurable list, e.g., major trade hubs).
    *   Use the ESI client (Task 02.1) to fetch public contracts for each region.
    *   For each contract, fetch its items.
    *   Transform ESI data into local `Contract` and `ContractItem` model instances.
    *   Implement logic for upserting data (insert new, update existing based on `contract_id` and ETag/last modified if available).
    *   Handle potential errors during fetching or processing gracefully (log and continue if possible).
    *   **AI Prompt:** "Outline a Python function that takes a `region_id`, uses the ESI client to fetch contracts and their items, and then prepares `Contract` and `ContractItem` SQLAlchemy objects for database insertion/update. Include basic error handling."
*   [ ] **Scheduling:**
    *   Configure the chosen scheduler (`APScheduler`) to run the aggregation logic at regular intervals (e.g., every 15-30 minutes, configurable).
    *   Ensure the scheduler is started when the FastAPI application starts.
    *   **AI Prompt:** "Show how to integrate `APScheduler` with a FastAPI application to run a specific async function periodically."
*   [ ] **Database Interaction:**
    *   Use SQLAlchemy sessions (from Task 01.2 `get_db` or a similar utility for background tasks) to interact with the database.
    *   Batch database operations where possible for efficiency.
*   [ ] **Logging:**
    *   Implement detailed logging for the aggregation process (start, end, number of contracts processed, errors encountered).

## 4. AI Implementation Guidance

*   Focus on resilience: the aggregator should handle ESI errors or temporary unavailability without crashing.
*   Make region list and schedule interval configurable (via Pydantic settings).
*   Ensure efficient database updates (upserts) to avoid duplicates and keep data current.
*   If using `APScheduler` with `asyncio`, ensure jobs are scheduled correctly in the event loop.

## 5. Definition of Done

*   A background task mechanism (`APScheduler` or similar) is integrated.
*   Aggregation logic to fetch, process, and store contract data for specified regions is implemented.
*   The aggregation task is scheduled to run periodically.
*   Data is correctly upserted into the `Contract` and `ContractItem` tables.
*   Adequate logging is in place for monitoring the aggregation process.
*   All new files and code changes are committed to version control.
