# Task 02.3: Background Aggregation Service

**Phase:** 02 - Backend - F001: Public Contract Aggregation
**Parent Plan:** [MVP Implementation Plan Overview](../00-mvp-implementation-plan-overview.md)
**Last Updated:** 2025-06-06

## 1. Objective

To implement a background service/task that periodically fetches public contract data from ESI for relevant regions, processes it, and stores/updates it in the local database using the defined data models and ESI client.

## 2. Relevant Specifications

*   `../../../design/design-spec.md` (Sections: Background Processing, Data Aggregation)
*   `../../../design/features/F001-Public-Contract-Aggregation-Display.md` (Data freshness requirements)
*   Task 02.1: ESI API Client (Public Endpoints)
*   Task 02.2: Data Models for F001

## 3. Key Implementation Steps

*   [ ] **Choose Background Task Framework:**
    *   Select a suitable framework for running background tasks with FastAPI (e.g., `FastAPI BackgroundTasks`, `Celery`, `ARQ`). For MVP, `FastAPI BackgroundTasks` or a simple scheduled script might suffice. `ARQ` is a good async-native option.
    *   **Decision Point:** For MVP, a simple scheduled task (e.g., using `APScheduler` within the FastAPI app or a separate script run by `cron`/`Scheduled Tasks`) might be simpler than full Celery/ARQ setup. Let's lean towards `APScheduler` integrated with FastAPI for now.
*   [ ] **Aggregation Logic:**
    *   Define the core aggregation function/service class.
    *   Iterate through target EVE Online regions (initially a configurable list, e.g., major trade hubs).
    *   Use the ESI client (Task 02.1) to fetch public contracts for each region.
    *   For each contract, fetch its items.
    *   For each unique `type_id` encountered in contract items, use the ESI client to fetch its details from `/universe/types/{type_id}/` and upsert this information into the `EsiTypeCache` table (Task 02.2). This should be done before or alongside processing contract items to ensure type data is available.
    *   Transform ESI data into local `Contract` and `ContractItem` model instances, linking to `EsiTypeCache` where appropriate (though direct FKs might not be necessary if `type_id` is consistently used).
    *   Implement logic for upserting data (insert new, update existing based on `contract_id` and ETag/last modified if available).
    *   Handle potential errors during fetching or processing gracefully (log and continue if possible).
    *   **AI Prompt:** "Outline a Python async function that takes a `region_id` and a database session. This function should: 1. Use an ESI client to fetch contracts for the region. 2. For each contract, fetch its items. 3. Collect all unique `type_id`s from all items. 4. For each unique `type_id`, fetch its details from ESI and prepare an `EsiTypeCache` SQLAlchemy object for upsert. 5. Prepare `Contract` and `ContractItem` SQLAlchemy objects. 6. Perform batched upserts for `EsiTypeCache`, then `Contract`, then `ContractItem` objects. Include robust error handling, logging, and ETag usage for ESI calls."
*   [ ] **Scheduling:**
    *   Configure the chosen scheduler (`APScheduler`) to run the aggregation logic at regular intervals (e.g., every 15-30 minutes, configurable).
    *   Ensure the scheduler is started when the FastAPI application starts.
    *   **AI Prompt:** "Show how to integrate `APScheduler` with a FastAPI application to run a specific async function periodically."
*   [ ] **Database Interaction:**
    *   Use SQLAlchemy sessions (from Task 01.2 `get_db` or a similar utility for background tasks) to interact with the database.
    *   Batch database operations where possible for efficiency.
*   [ ] **Logging:**
    *   Implement detailed logging for the aggregation process (start, end, number of contracts processed, errors encountered).

## 4. AI Implementation Guidance

*   Focus on resilience: the aggregator should handle ESI errors or temporary unavailability without crashing.
*   Make region list and schedule interval configurable (via Pydantic settings).
*   Ensure efficient database updates (upserts) to avoid duplicates and keep data current.
*   If using `APScheduler` with `asyncio`, ensure jobs are scheduled correctly in the event loop.

## 5. Definition of Done

*   A background task mechanism (`APScheduler` or similar) is integrated.
*   Aggregation logic to fetch, process, and store contract data for specified regions is implemented.
*   The aggregation task is scheduled to run periodically.
*   Data is correctly upserted into the `Contract` and `ContractItem` tables.
*   Adequate logging is in place for monitoring the aggregation process.
*   All new files and code changes are committed to version control.

## 6. Cross-Cutting Concerns Review

This section documents how the five key cross-cutting concerns were addressed during the completion of this task. Refer to the primary specification documents for detailed guidance:
*   Security: `../../../design/security-spec.md`
*   Observability: `../../../design/observability-spec.md`
*   Testing: `../../../design/test-spec.md`
*   Accessibility: `../../../design/accessibility-spec.md`
*   Internationalization (i18n): `../../../design/i18n-spec.md`

### 1. Security
*   [ ] **Secure Design:** (e.g., threat modeling, principle of least privilege)
*   [ ] **Input Validation:** (e.g., validating all external inputs)
*   [ ] **Output Encoding:** (e.g., preventing XSS)
*   [ ] **Authentication/Authorization:** (e.g., ensuring proper checks)
*   [ ] **Secrets Management:** (e.g., secure storage and access)
*   [ ] **Dependency Management:** (e.g., checking for vulnerable libraries)
*   **Notes:** (Detail specific actions taken or rationale for no action, especially if a category is not applicable to this task.)

### 2. Observability
*   [ ] **Structured Logging:** (e.g., using key-value pairs, JSON format)
*   [ ] **Key Events Logged:** (e.g., task initiation, completion, critical errors, significant state changes)
*   [ ] **Error Logging:** (e.g., comprehensive error details, stack traces)
*   [ ] **Correlation IDs:** (e.g., for tracing requests across services)
*   [ ] **Metrics:** (e.g., performance indicators, resource usage - if applicable)
*   **Notes:** (Detail specific actions taken or rationale for no action.)

### 3. Testing
*   [ ] **Unit Tests:** (e.g., for new functions, classes, components)
*   [ ] **Integration Tests:** (e.g., for interactions between components/services)
*   [ ] **Test Coverage:** (e.g., summary of coverage achieved or targeted)
*   [ ] **Test Data Management:** (e.g., how test data is sourced/managed)
*   **Notes:** (Detail specific actions taken or rationale for no action.)

### 4. Accessibility (A11y)
*(Primarily for UI-related tasks, but consider CLI/API accessibility where relevant)*
*   [ ] **Semantic HTML/Structure:** (e.g., using appropriate tags for meaning)
*   [ ] **ARIA Attributes:** (e.g., for dynamic content or custom controls)
*   [ ] **Keyboard Navigability:** (e.g., all interactive elements reachable and operable via keyboard)
*   [ ] **Color Contrast:** (e.g., ensuring sufficient contrast for text and UI elements)
*   [ ] **Screen Reader Compatibility:** (e.g., testing with screen readers)
*   [ ] **Alternative Text for Images:** (e.g., providing descriptive alt text)
*   **Notes:** (Detail specific actions taken or rationale for no action, especially if not UI-related.)

### 5. Internationalization (I18n)
*(Primarily for UI-related tasks, but consider for any user-facing text including logs/error messages)*
*   [ ] **Text Abstraction:** (e.g., using translation keys instead of hardcoded strings)
*   [ ] **Locale-Specific Formatting:** (e.g., for dates, numbers, currencies)
*   [ ] **UI Layout Adaptability:** (e.g., for text expansion in different languages)
*   [ ] **Character Encoding:** (e.g., using UTF-8)
*   **Notes:** (Detail specific actions taken or rationale for no action, especially if not UI-related.)

---
<!-- This section should be placed before any final "Task Completion Checklist" or similar concluding remarks. -->
